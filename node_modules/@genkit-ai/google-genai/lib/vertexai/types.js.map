{"version":3,"sources":["../../src/vertexai/types.ts"],"sourcesContent":["/**\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GoogleAuth, GoogleAuthOptions } from 'google-auth-library';\nimport {\n  CitationMetadata,\n  CodeExecutionTool,\n  Content,\n  FunctionCallingMode,\n  FunctionDeclarationsTool,\n  GenerateContentCandidate,\n  GenerateContentRequest,\n  GenerateContentResponse,\n  GenerateContentStreamResult,\n  GoogleMaps,\n  GoogleMapsTool,\n  GoogleSearchRetrieval,\n  GoogleSearchRetrievalTool,\n  GroundingMetadata,\n  HarmBlockThreshold,\n  HarmCategory,\n  ImagenInstance,\n  ImagenParameters,\n  ImagenPredictRequest,\n  ImagenPredictResponse,\n  ImagenPrediction,\n  RetrievalTool,\n  TaskType,\n  TaskTypeSchema,\n  Tool,\n  ToolConfig,\n  isCodeExecutionTool,\n  isFunctionDeclarationsTool,\n  isGoogleMapsTool,\n  isGoogleSearchRetrievalTool,\n  isObject,\n  isRetrievalTool,\n} from '../common/types.js';\n\n// This makes it easier to import all types from one place\nexport {\n  FunctionCallingMode,\n  HarmBlockThreshold,\n  HarmCategory,\n  TaskTypeSchema,\n  isCodeExecutionTool,\n  isFunctionDeclarationsTool,\n  isGoogleMapsTool,\n  isGoogleSearchRetrievalTool,\n  isObject,\n  isRetrievalTool,\n  type CitationMetadata,\n  type CodeExecutionTool,\n  type Content,\n  type FunctionDeclarationsTool,\n  type GenerateContentCandidate,\n  type GenerateContentRequest,\n  type GenerateContentResponse,\n  type GenerateContentStreamResult,\n  type GoogleMaps,\n  type GoogleMapsTool,\n  type GoogleSearchRetrieval,\n  type GoogleSearchRetrievalTool,\n  type GroundingMetadata,\n  type ImagenInstance,\n  type ImagenParameters,\n  type ImagenPredictRequest,\n  type ImagenPredictResponse,\n  type ImagenPrediction,\n  type RetrievalTool,\n  type Tool,\n  type ToolConfig,\n};\n\n/** Options for Vertex AI plugin configuration */\nexport interface VertexPluginOptions {\n  /** The Vertex API key for express mode */\n  apiKey?: string | false;\n  /** The Google Cloud project id to call. */\n  projectId?: string;\n  /** The Google Cloud region to call. */\n  location?: string;\n  /** Provide custom authentication configuration for connecting to Vertex AI. */\n  googleAuth?: GoogleAuthOptions;\n  /** Enables additional debug traces (e.g. raw model API call details). */\n  experimental_debugTraces?: boolean;\n  /** Use `responseSchema` field instead of `responseJsonSchema`. */\n  legacyResponseSchema?: boolean;\n}\n\ninterface BaseClientOptions {\n  /** timeout in milli seconds. time out value needs to be non negative. */\n  timeout?: number;\n  signal?: AbortSignal;\n}\n\nexport interface RegionalClientOptions extends BaseClientOptions {\n  kind: 'regional';\n  location: string;\n  projectId: string;\n  authClient: GoogleAuth;\n  apiKey?: string; // In addition to regular auth\n}\n\nexport interface GlobalClientOptions extends BaseClientOptions {\n  kind: 'global';\n  location: 'global';\n  projectId: string;\n  authClient: GoogleAuth;\n  apiKey?: string; // In addition to regular auth\n}\n\nexport interface ExpressClientOptions extends BaseClientOptions {\n  kind: 'express';\n  apiKey: string | false | undefined; // Instead of regular auth\n}\n\n/** Resolved options for use with the client */\nexport type ClientOptions =\n  | RegionalClientOptions\n  | GlobalClientOptions\n  | ExpressClientOptions;\n\n/**\n * Request options params.\n */\nexport interface RequestOptions {\n  /** an apiKey to use for this request if applicable */\n  apiKey?: string | false | undefined;\n  /** timeout in milli seconds. time out value needs to be non negative. */\n  timeout?: number;\n  /**\n   * Version of API endpoint to call (e.g. \"v1\" or \"v1beta\"). If not specified,\n   * defaults to 'v1beta'.\n   */\n  apiVersion?: string;\n  /**\n   * Value for x-goog-api-client header to set on the API request. This is\n   * intended for wrapper SDKs to set additional SDK identifiers for the\n   * backend.\n   */\n  apiClient?: string;\n  /**\n   * Value for custom HTTP headers to set on the HTTP request.\n   */\n  customHeaders?: Headers;\n}\n\n// Vertex AI  model definition\nexport interface Model {\n  name: string;\n  launchStage: string;\n}\n\n// Vertex AI list models response\nexport interface ListModelsResponse {\n  publisherModels: Model[];\n}\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#request_body\ninterface TextEmbeddingInstance {\n  task_type?: TaskType;\n  content: string;\n  title?: string;\n}\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings-api#request_body\ninterface MultimodalEmbeddingInstance {\n  text?: string;\n  image?: {\n    // Union field can only be one of the following:\n    bytesBase64Encoded?: string;\n    gcsUri?: string;\n    // End of list of possible types for union field.\n    mimeType?: string;\n  };\n  video?: {\n    // Union field can only be one of the following:\n    bytesBase64Encoded?: string;\n    gcsUri?: string;\n    // End of list of possible types for union field.\n    videoSegmentConfig?: {\n      startOffsetSec: number;\n      endOffsetSec: number;\n      intervalSec: number;\n    };\n  };\n  parameters?: {\n    dimension: number;\n  };\n}\n\nexport declare type EmbeddingInstance =\n  | TextEmbeddingInstance\n  | MultimodalEmbeddingInstance;\n\nexport declare interface TextEmbeddingPrediction {\n  embeddings: {\n    statistics: {\n      truncated: boolean;\n      token_count: number;\n    };\n    values: number[];\n  };\n}\n\nexport declare interface VideoEmbedding {\n  startOffsetSec: number;\n  endOffsetSec: number;\n  embedding: number[];\n}\n\nexport declare interface MultimodalEmbeddingPrediction {\n  textEmbedding?: number[];\n  imageEmbedding?: number[];\n  videoEmbeddings?: VideoEmbedding[];\n}\n\nexport function isMultimodalEmbeddingPrediction(\n  value: unknown\n): value is MultimodalEmbeddingPrediction {\n  if (!isObject(value)) {\n    return false;\n  }\n  if (!value.textEmbedding && !value.imageEmbedding && !value.videoEmbeddings) {\n    return false;\n  }\n  if (value.textEmbedding && !Array.isArray(value.textEmbedding)) {\n    return false;\n  }\n  if (value.imageEmbedding && !Array.isArray(value.imageEmbedding)) {\n    return false;\n  }\n  if (value.videoEmbeddings && !Array.isArray(value.videoEmbeddings)) {\n    return false;\n  }\n  if (value.videoEmbeddings) {\n    for (const emb of value.videoEmbeddings as Array<unknown>) {\n      if (!isObject(emb)) {\n        return false;\n      }\n      if (!emb.embedding || !Array.isArray(emb.embedding)) {\n        return false;\n      }\n    }\n  }\n\n  return true;\n}\n\nexport declare type EmbeddingPrediction =\n  | TextEmbeddingPrediction\n  | MultimodalEmbeddingPrediction;\n\nexport declare interface EmbedContentRequest {\n  instances: EmbeddingInstance[];\n  parameters: EmbedContentConfig;\n}\n\nexport declare interface EmbedContentResponse {\n  predictions: EmbeddingPrediction[];\n}\n\n/** Optional parameters for the embed content method. */\nexport declare interface EmbedContentConfig {\n  /** Type of task for which the embedding will be used. */\n  taskType?: string;\n  /** Title for the text. Only applicable when TaskType is\n      `RETRIEVAL_DOCUMENT`.\n       */\n  title?: string;\n  /** Reduced dimension for the output embedding. If set,\n      excessive values in the output embedding are truncated from the end.\n      Supported by newer models since 2024 only. You cannot set this value if\n      using the earlier model (`models/embedding-001`).\n       */\n  outputDimensionality?: number;\n  /** The MIME type of the input. */\n  mimeType?: string;\n  /** Vertex API only. Whether to silently truncate inputs longer than\n      the max sequence length. If this option is set to false, oversized inputs\n      will lead to an INVALID_ARGUMENT error, similar to other text APIs.\n       */\n  autoTruncate?: boolean;\n}\n\nexport declare type EmbeddingResult = {\n  embedding: number[];\n  metadata?: Record<string, unknown>;\n};\n\nexport declare interface VeoMedia {\n  bytesBase64Encoded?: string;\n  gcsUri?: string;\n  mimeType?: string;\n}\n\nexport declare interface VeoReferenceImage {\n  image: VeoMedia;\n  referenceType: string;\n}\n\nexport declare interface VeoMask extends VeoMedia {\n  mask: string;\n}\n\nexport declare interface VeoInstance {\n  prompt: string;\n  image?: VeoMedia;\n  lastFrame?: VeoMedia;\n  video?: VeoMedia;\n  referenceImages?: VeoReferenceImage[];\n}\n\nexport declare interface VeoParameters {\n  aspectRatio?: string;\n  durationSeconds?: number;\n  enhancePrompt?: boolean;\n  generateAudio?: boolean;\n  negativePrompt?: string;\n  personGeneration?: string;\n  resolution?: string; // Veo 3\n  sampleCount?: number;\n  seed?: number;\n  storageUri?: string;\n}\n\nexport declare interface VeoPredictRequest {\n  instances: VeoInstance[];\n  parameters: VeoParameters;\n}\n\nexport declare interface Operation {\n  name: string;\n  done?: boolean;\n  error?: {\n    code: number;\n    message: string;\n    details?: unknown;\n  };\n  clientOptions?: ClientOptions; // Added so we can call check with the same ones\n}\n\nexport declare interface VeoOperation extends Operation {\n  response?: {\n    raiMediaFilteredCount?: number;\n    videos: VeoMedia[];\n  };\n}\n\nexport declare interface VeoOperationRequest {\n  operationName: string;\n}\n\nexport declare interface LyriaParameters {\n  sampleCount?: number;\n}\n\nexport declare interface LyriaPredictRequest {\n  instances: LyriaInstance[];\n  parameters: LyriaParameters;\n}\n\nexport declare interface LyriaPredictResponse {\n  predictions: LyriaPrediction[];\n}\n\nexport declare interface LyriaPrediction {\n  bytesBase64Encoded: string; // Base64 encoded Wav string\n  mimeType: string; // audio/wav\n}\n\nexport declare interface LyriaInstance {\n  prompt: string;\n  negativePrompt?: string;\n  seed?: number;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAiBA,mBAiCO;AAqLA,SAAS,gCACd,OACwC;AACxC,MAAI,KAAC,uBAAS,KAAK,GAAG;AACpB,WAAO;AAAA,EACT;AACA,MAAI,CAAC,MAAM,iBAAiB,CAAC,MAAM,kBAAkB,CAAC,MAAM,iBAAiB;AAC3E,WAAO;AAAA,EACT;AACA,MAAI,MAAM,iBAAiB,CAAC,MAAM,QAAQ,MAAM,aAAa,GAAG;AAC9D,WAAO;AAAA,EACT;AACA,MAAI,MAAM,kBAAkB,CAAC,MAAM,QAAQ,MAAM,cAAc,GAAG;AAChE,WAAO;AAAA,EACT;AACA,MAAI,MAAM,mBAAmB,CAAC,MAAM,QAAQ,MAAM,eAAe,GAAG;AAClE,WAAO;AAAA,EACT;AACA,MAAI,MAAM,iBAAiB;AACzB,eAAW,OAAO,MAAM,iBAAmC;AACzD,UAAI,KAAC,uBAAS,GAAG,GAAG;AAClB,eAAO;AAAA,MACT;AACA,UAAI,CAAC,IAAI,aAAa,CAAC,MAAM,QAAQ,IAAI,SAAS,GAAG;AACnD,eAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;","names":[]}