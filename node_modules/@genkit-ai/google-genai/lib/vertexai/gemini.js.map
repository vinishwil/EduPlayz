{"version":3,"sources":["../../src/vertexai/gemini.ts"],"sourcesContent":["/**\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ActionMetadata, GenkitError, modelActionMetadata, z } from 'genkit';\nimport {\n  CandidateData,\n  GenerationCommonConfigDescriptions,\n  GenerationCommonConfigSchema,\n  ModelAction,\n  ModelInfo,\n  ModelMiddleware,\n  ModelReference,\n  getBasicUsageStats,\n  modelRef,\n} from 'genkit/model';\nimport { downloadRequestMedia } from 'genkit/model/middleware';\nimport { model as pluginModel } from 'genkit/plugin';\nimport { runInNewSpan } from 'genkit/tracing';\nimport {\n  fromGeminiCandidate,\n  toGeminiFunctionModeEnum,\n  toGeminiMessage,\n  toGeminiSystemInstruction,\n  toGeminiTool,\n} from '../common/converters.js';\nimport {\n  generateContent,\n  generateContentStream,\n  getVertexAIUrl,\n} from './client.js';\nimport { toGeminiLabels, toGeminiSafetySettings } from './converters.js';\nimport {\n  ClientOptions,\n  Content,\n  GenerateContentRequest,\n  GenerateContentResponse,\n  GoogleSearchRetrieval,\n  GoogleSearchRetrievalTool,\n  Model,\n  Tool,\n  ToolConfig,\n  VertexPluginOptions,\n} from './types.js';\nimport {\n  calculateRequestOptions,\n  checkModelName,\n  cleanSchema,\n  extractVersion,\n  modelName,\n} from './utils.js';\n\nexport const SafetySettingsSchema = z\n  .object({\n    category: z.enum([\n      /** The harm category is unspecified. */\n      'HARM_CATEGORY_UNSPECIFIED',\n      /** The harm category is hate speech. */\n      'HARM_CATEGORY_HATE_SPEECH',\n      /** The harm category is dangerous content. */\n      'HARM_CATEGORY_DANGEROUS_CONTENT',\n      /** The harm category is harassment. */\n      'HARM_CATEGORY_HARASSMENT',\n      /** The harm category is sexually explicit content. */\n      'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n    ]),\n    threshold: z.enum([\n      'BLOCK_LOW_AND_ABOVE',\n      'BLOCK_MEDIUM_AND_ABOVE',\n      'BLOCK_ONLY_HIGH',\n      'BLOCK_NONE',\n    ]),\n  })\n  .passthrough();\n\nconst VertexRetrievalSchema = z\n  .object({\n    datastore: z\n      .object({\n        projectId: z.string().describe('Google Cloud Project ID.').optional(),\n        location: z\n          .string()\n          .describe('Google Cloud region e.g. us-central1.')\n          .optional(),\n        dataStoreId: z\n          .string()\n          .describe(\n            'The data store id, when project id and location are provided as ' +\n              'separate options. Alternatively, the full path to the data ' +\n              'store should be provided in the form: \"projects/{project}/' +\n              'locations/{location}/collections/default_collection/dataStores/{data_store}\".'\n          ),\n      })\n      .describe('Vertex AI Search data store details')\n      .passthrough(),\n    disableAttribution: z\n      .boolean()\n      .describe(\n        'Disable using the search data in detecting grounding attribution. This ' +\n          'does not affect how the result is given to the model for generation.'\n      )\n      .optional(),\n  })\n  .passthrough();\n\nconst GoogleSearchRetrievalSchema = z\n  .object({\n    disableAttribution: z\n      .boolean()\n      .describe(\n        'Disable using the search data in detecting grounding attribution. This ' +\n          'does not affect how the result is given to the model for generation.'\n      )\n      .optional(),\n  })\n  .passthrough();\n\n/**\n * Zod schema of Gemini model options.\n * Please refer to: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#generationconfig, for further information.\n */\nexport const GeminiConfigSchema = GenerationCommonConfigSchema.extend({\n  apiKey: z\n    .string()\n    .describe('Overrides the plugin-configured API key, if specified.')\n    .optional(),\n  labels: z\n    .record(z.string())\n    .optional()\n    .describe('Key-value labels to attach to the request for cost tracking.'),\n  temperature: z\n    .number()\n    .min(0.0)\n    .max(2.0)\n    .describe(\n      GenerationCommonConfigDescriptions.temperature +\n        ' The default value is 1.0.'\n    )\n    .optional(),\n  topP: z\n    .number()\n    .min(0)\n    .max(1.0)\n    .describe(\n      GenerationCommonConfigDescriptions.topP + ' The default value is 0.95.'\n    )\n    .optional(),\n  location: z\n    .string()\n    .describe('Google Cloud region e.g. us-central1.')\n    .optional(),\n\n  /**\n   * Safety filter settings. See: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters#configurable-filters\n   *\n   * E.g.\n   *\n   * ```js\n   * config: {\n   *   safetySettings: [\n   *     {\n   *       category: 'HARM_CATEGORY_HATE_SPEECH',\n   *       threshold: 'BLOCK_LOW_AND_ABOVE',\n   *     },\n   *     {\n   *       category: 'HARM_CATEGORY_DANGEROUS_CONTENT',\n   *       threshold: 'BLOCK_MEDIUM_AND_ABOVE',\n   *     },\n   *     {\n   *       category: 'HARM_CATEGORY_HARASSMENT',\n   *       threshold: 'BLOCK_ONLY_HIGH',\n   *     },\n   *     {\n   *       category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n   *       threshold: 'BLOCK_NONE',\n   *     },\n   *   ],\n   * }\n   * ```\n   */\n  safetySettings: z\n    .array(SafetySettingsSchema)\n    .describe(\n      'Adjust how likely you are to see responses that could be harmful. ' +\n        'Content is blocked based on the probability that it is harmful.'\n    )\n    .optional(),\n\n  /**\n   * Vertex retrieval options.\n   *\n   * E.g.\n   *\n   * ```js\n   *   config: {\n   *     vertexRetrieval: {\n   *       datastore: {\n   *         projectId: 'your-cloud-project',\n   *         location: 'us-central1',\n   *         collection: 'your-collection',\n   *       },\n   *       disableAttribution: true,\n   *     }\n   *   }\n   * ```\n   */\n  vertexRetrieval: VertexRetrievalSchema.describe(\n    'Retrieve from Vertex AI Search data store for grounding ' +\n      'generative responses.'\n  ).optional(),\n\n  /**\n   * Google Search retrieval options.\n   *\n   * ```js\n   *   config: {\n   *     googleSearchRetrieval: {\n   *       disableAttribution: true,\n   *     }\n   *   }\n   * ```\n   */\n  googleSearchRetrieval: GoogleSearchRetrievalSchema.describe(\n    'Retrieve public web data for grounding, powered by Google Search.'\n  ).optional(),\n\n  /**\n   * Function calling options.\n   *\n   * E.g. forced tool call:\n   *\n   * ```js\n   *   config: {\n   *     functionCallingConfig: {\n   *       mode: 'ANY',\n   *     }\n   *   }\n   * ```\n   */\n  functionCallingConfig: z\n    .object({\n      mode: z.enum(['MODE_UNSPECIFIED', 'AUTO', 'ANY', 'NONE']).optional(),\n      allowedFunctionNames: z.array(z.string()).optional(),\n      /**\n       * When set to true, arguments of a single function call will be streamed out in\n       * multiple parts/contents/responses. Partial parameter results will be returned in the\n       * [FunctionCall.partial_args] field. This field is not supported in Gemini API.\n       */\n      streamFunctionCallArguments: z.boolean().optional(),\n    })\n    .describe(\n      'Controls how the model uses the provided tools (function declarations). ' +\n        'With AUTO (Default) mode, the model decides whether to generate a ' +\n        'natural language response or suggest a function call based on the ' +\n        'prompt and context. With ANY, the model is constrained to always ' +\n        'predict a function call and guarantee function schema adherence. ' +\n        'With NONE, the model is prohibited from making function calls.'\n    )\n    .passthrough()\n    .optional(),\n  /**\n   * Retrieval config for search grounding and maps grounding\n   */\n  retrievalConfig: z\n    .object({\n      /**\n       * User location for search grounding or\n       * place location for maps grounding.\n       */\n      latLng: z\n        .object({\n          latitude: z.number().optional(),\n          longitude: z.number().optional(),\n        })\n        .describe('User location for Google search or Google maps grounding.')\n        .optional(),\n      /**\n       * Language code for the request. e.g. 'en-us'\n       */\n      languageCode: z.string().optional(),\n    })\n    .passthrough()\n    .optional(),\n  thinkingConfig: z\n    .object({\n      includeThoughts: z\n        .boolean()\n        .describe(\n          'Indicates whether to include thoughts in the response.' +\n            'If true, thoughts are returned only if the model supports ' +\n            'thought and thoughts are available.'\n        )\n        .optional(),\n      thinkingBudget: z\n        .number()\n        .min(0)\n        .max(24576)\n        .describe(\n          'For Gemini 2.5 - Indicates the thinking budget in tokens. 0 is DISABLED. ' +\n            '-1 is AUTOMATIC. The default values and allowed ranges are model ' +\n            'dependent. The thinking budget parameter gives the model guidance ' +\n            'on the number of thinking tokens it can use when generating a ' +\n            'response. A greater number of tokens is typically associated with ' +\n            'more detailed thinking, which is needed for solving more complex ' +\n            'tasks. '\n        )\n        .optional(),\n      thinkingLevel: z\n        .enum(['LOW', 'MEDIUM', 'HIGH'])\n        .describe(\n          'For Gemini 3.0 - Indicates the thinking level. A higher level ' +\n            'is associated with more detailed thinking, which is needed for solving ' +\n            'more complex tasks.'\n        )\n        .optional(),\n    })\n    .passthrough()\n    .optional(),\n}).passthrough();\nexport type GeminiConfigSchemaType = typeof GeminiConfigSchema;\n/**\n * Gemini model configuration options.\n *\n * E.g.\n * ```js\n *   config: {\n *     temperature: 0.9,\n *     maxOutputTokens: 300,\n *     safetySettings: [\n *       {\n *         category: 'HARM_CATEGORY_HATE_SPEECH',\n *         threshold: 'BLOCK_LOW_AND_ABOVE',\n *       },\n *       {\n *         category: 'HARM_CATEGORY_DANGEROUS_CONTENT',\n *         threshold: 'BLOCK_MEDIUM_AND_ABOVE',\n *       },\n *       {\n *         category: 'HARM_CATEGORY_HARASSMENT',\n *         threshold: 'BLOCK_ONLY_HIGH',\n *       },\n *       {\n *         category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n *         threshold: 'BLOCK_NONE',\n *       },\n *     ],\n *     functionCallingConfig: {\n *       mode: 'ANY',\n *     }\n *   }\n * ```\n */\nexport type GeminiConfig = z.infer<GeminiConfigSchemaType>;\n\nexport const GeminiImageConfigSchema = GeminiConfigSchema.extend({\n  imageConfig: z\n    .object({\n      aspectRatio: z\n        .enum([\n          '1:1',\n          '2:3',\n          '3:2',\n          '3:4',\n          '4:3',\n          '4:5',\n          '5:4',\n          '9:16',\n          '16:9',\n          '21:9',\n        ])\n        .optional(),\n      imageSize: z.enum(['1K', '2K', '4K']).optional(),\n    })\n    .passthrough()\n    .optional(),\n}).passthrough();\nexport type GeminiImageConfigSchemaType = typeof GeminiImageConfigSchema;\nexport type GeminiImageConfig = z.infer<GeminiImageConfigSchemaType>;\n\n// This contains all the Gemini config schema types\ntype ConfigSchemaType = GeminiConfigSchemaType | GeminiImageConfigSchemaType;\ntype ConfigSchema = z.infer<ConfigSchemaType>;\n\nfunction commonRef(\n  name: string,\n  info?: ModelInfo,\n  configSchema: ConfigSchemaType = GeminiConfigSchema\n): ModelReference<ConfigSchemaType> {\n  return modelRef({\n    name: `vertexai/${name}`,\n    configSchema,\n    info: info ?? {\n      supports: {\n        multiturn: true,\n        media: true,\n        tools: true,\n        toolChoice: true,\n        systemRole: true,\n        constrained: 'no-tools',\n      },\n    },\n  });\n}\n\nconst GENERIC_MODEL = commonRef('gemini');\nconst GENERIC_IMAGE_MODEL = commonRef(\n  'gemini-image',\n  undefined,\n  GeminiImageConfigSchema\n);\n\nexport const KNOWN_GEMINI_MODELS = {\n  'gemini-3-pro-preview': commonRef('gemini-3-pro-preview'),\n  'gemini-2.5-flash-lite': commonRef('gemini-2.5-flash-lite'),\n  'gemini-2.5-pro': commonRef('gemini-2.5-pro'),\n  'gemini-2.5-flash': commonRef('gemini-2.5-flash'),\n  'gemini-2.0-flash-001': commonRef('gemini-2.0-flash-001'),\n  'gemini-2.0-flash': commonRef('gemini-2.0-flash'),\n  'gemini-2.0-flash-lite': commonRef('gemini-2.0-flash-lite'),\n  'gemini-2.0-flash-lite-001': commonRef('gemini-2.0-flash-lite-001'),\n} as const;\nexport type KnownGeminiModels = keyof typeof KNOWN_GEMINI_MODELS;\nexport type GeminiModelName = `gemini-${string}`;\nexport function isGeminiModelName(value?: string): value is GeminiModelName {\n  return !!(\n    value?.startsWith('gemini-') &&\n    !value.includes('embedding') &&\n    !value.includes('-image')\n  );\n}\n\nexport const KNOWN_IMAGE_MODELS = {\n  'gemini-3-pro-image-preview': commonRef(\n    'gemini-3-pro-image-preview',\n    { ...GENERIC_IMAGE_MODEL.info },\n    GeminiImageConfigSchema\n  ),\n  'gemini-2.5-flash-image': commonRef(\n    'gemini-2.5-flash-image',\n    undefined,\n    GeminiImageConfigSchema\n  ),\n} as const;\nexport type KnownImageModels = keyof typeof KNOWN_IMAGE_MODELS;\nexport type ImageModelName = `gemini-${string}-image${string}`;\nexport function isImageModelName(value?: string): value is ImageModelName {\n  return !!(value?.startsWith('gemini-') && value.includes('-image'));\n}\n\nconst KNOWN_MODELS = {\n  ...KNOWN_GEMINI_MODELS,\n  ...KNOWN_IMAGE_MODELS,\n};\nexport type KnownModels = keyof typeof KNOWN_MODELS;\n\nexport function model(\n  version: string,\n  config: ConfigSchema = {}\n): ModelReference<ConfigSchemaType> {\n  const name = checkModelName(version);\n\n  if (isImageModelName(name)) {\n    return modelRef({\n      name: `vertexai/${name}`,\n      config,\n      configSchema: GeminiImageConfigSchema,\n      info: { ...GENERIC_IMAGE_MODEL.info },\n    });\n  }\n\n  return modelRef({\n    name: `vertexai/${name}`,\n    config,\n    configSchema: GeminiConfigSchema,\n    info: {\n      ...GENERIC_MODEL.info,\n    },\n  });\n}\n\nexport function listActions(models: Model[]): ActionMetadata[] {\n  const KNOWN_DECOMISSIONED_MODELS = [\n    'gemini-pro-vision',\n    'gemini-pro',\n    'gemini-ultra',\n    'gemini-ultra-vision',\n  ];\n\n  return models\n    .filter(\n      (m) =>\n        (isGeminiModelName(modelName(m.name)) ||\n          isImageModelName(modelName(m.name))) &&\n        !KNOWN_DECOMISSIONED_MODELS.includes(modelName(m.name) || '')\n    )\n    .map((m) => {\n      const ref = model(m.name);\n      return modelActionMetadata({\n        name: ref.name,\n        info: ref.info,\n        configSchema: ref.configSchema,\n      });\n    });\n}\n\nexport function listKnownModels(\n  clientOptions: ClientOptions,\n  pluginOptions?: VertexPluginOptions\n) {\n  return Object.keys(KNOWN_MODELS).map((name) =>\n    defineModel(name, clientOptions, pluginOptions)\n  );\n}\n\n/**\n * Define a Vertex AI Gemini model.\n */\nexport function defineModel(\n  name: string,\n  clientOptions: ClientOptions,\n  pluginOptions?: VertexPluginOptions\n): ModelAction {\n  const ref = model(name);\n  const middlewares: ModelMiddleware[] = [];\n  if (ref.info?.supports?.media) {\n    // the gemini api doesn't support downloading media from http(s)\n    middlewares.push(\n      downloadRequestMedia({\n        maxBytes: 1024 * 1024 * 20,\n        filter: (part) => {\n          try {\n            const url = new URL(part.media.url);\n            if (\n              // Gemini can handle these URLs\n              ['www.youtube.com', 'youtube.com', 'youtu.be'].includes(\n                url.hostname\n              )\n            )\n              return false;\n          } catch {}\n          return true;\n        },\n      })\n    );\n  }\n\n  return pluginModel(\n    {\n      name: ref.name,\n      ...ref.info,\n      configSchema: ref.configSchema,\n      use: middlewares,\n    },\n    async (request, { streamingRequested, sendChunk, abortSignal }) => {\n      let clientOpt = { ...clientOptions, signal: abortSignal };\n\n      // Make a copy of messages to avoid side-effects\n      const messages = structuredClone(request.messages);\n      if (messages.length === 0) throw new Error('No messages provided.');\n\n      // Handle system instructions separately\n      let systemInstruction: Content | undefined = undefined;\n      const systemMessage = messages.find((m) => m.role === 'system');\n      if (systemMessage) {\n        messages.splice(messages.indexOf(systemMessage), 1);\n        systemInstruction = toGeminiSystemInstruction(systemMessage);\n      }\n\n      const requestConfig: ConfigSchema = { ...request.config };\n\n      const {\n        apiKey: apiKeyFromConfig,\n        functionCallingConfig,\n        retrievalConfig,\n        version: versionFromConfig,\n        googleSearchRetrieval,\n        tools: toolsFromConfig,\n        vertexRetrieval,\n        location,\n        safetySettings,\n        labels: labelsFromConfig,\n        ...restOfConfig\n      } = requestConfig;\n\n      clientOpt = calculateRequestOptions(clientOpt, {\n        location,\n        apiKey: apiKeyFromConfig,\n      });\n\n      const labels = toGeminiLabels(labelsFromConfig);\n\n      const tools: Tool[] = [];\n      if (request.tools?.length) {\n        tools.push({\n          functionDeclarations: request.tools.map(toGeminiTool),\n        });\n      }\n\n      let toolConfig: ToolConfig | undefined;\n      if (functionCallingConfig) {\n        toolConfig = {\n          functionCallingConfig: {\n            ...functionCallingConfig,\n            allowedFunctionNames: functionCallingConfig.allowedFunctionNames,\n            mode: toGeminiFunctionModeEnum(functionCallingConfig.mode),\n          },\n        };\n      } else if (request.toolChoice) {\n        toolConfig = {\n          functionCallingConfig: {\n            mode: toGeminiFunctionModeEnum(request.toolChoice),\n          },\n        };\n      }\n\n      if (retrievalConfig) {\n        if (!toolConfig) {\n          toolConfig = {};\n        }\n        toolConfig.retrievalConfig = structuredClone(retrievalConfig);\n      }\n\n      // Cannot use tools and function calling at the same time\n      const jsonMode =\n        (request.output?.format === 'json' || !!request.output?.schema) &&\n        tools.length === 0;\n\n      if (toolsFromConfig) {\n        tools.push(...(toolsFromConfig as any[]));\n      }\n\n      if (googleSearchRetrieval) {\n        // Gemini 1.5 models use googleSearchRetrieval, newer models use googleSearch.\n        if (ref.name.startsWith('vertexai/gemini-1.5')) {\n          tools.push({\n            googleSearchRetrieval:\n              googleSearchRetrieval as GoogleSearchRetrieval,\n          } as GoogleSearchRetrievalTool);\n        } else {\n          tools.push({\n            googleSearch: googleSearchRetrieval as GoogleSearchRetrieval,\n          } as GoogleSearchRetrievalTool);\n        }\n      }\n\n      if (vertexRetrieval) {\n        const _projectId =\n          vertexRetrieval.datastore.projectId ||\n          (clientOptions.kind != 'express'\n            ? clientOptions.projectId\n            : undefined);\n        const _location =\n          vertexRetrieval.datastore.location ||\n          (clientOptions.kind == 'regional'\n            ? clientOptions.location\n            : undefined);\n        const _dataStoreId = vertexRetrieval.datastore.dataStoreId;\n        if (!_projectId || !_location || !_dataStoreId) {\n          throw new GenkitError({\n            status: 'INVALID_ARGUMENT',\n            message:\n              'projectId, location and datastoreId are required for vertexRetrieval and could not be determined from configuration',\n          });\n        }\n        const datastore = `projects/${_projectId}/locations/${_location}/collections/default_collection/dataStores/${_dataStoreId}`;\n        tools.push({\n          retrieval: {\n            vertexAiSearch: {\n              datastore,\n            },\n            disableAttribution: vertexRetrieval.disableAttribution,\n          },\n        });\n      }\n\n      const generateContentRequest: GenerateContentRequest = {\n        systemInstruction,\n        generationConfig: {\n          ...restOfConfig,\n          candidateCount: request.candidates || undefined,\n          responseMimeType: jsonMode ? 'application/json' : undefined,\n        },\n        tools,\n        toolConfig,\n        safetySettings: toGeminiSafetySettings(safetySettings),\n        contents: messages.map((message) => toGeminiMessage(message, ref)),\n        labels,\n      };\n\n      const modelVersion = versionFromConfig || extractVersion(ref);\n\n      if (jsonMode && request.output?.constrained) {\n        if (pluginOptions?.legacyResponseSchema) {\n          generateContentRequest.generationConfig!.responseSchema = cleanSchema(\n            request.output.schema\n          );\n        } else {\n          generateContentRequest.generationConfig!.responseJsonSchema =\n            request.output.schema;\n        }\n      }\n\n      const callGemini = async () => {\n        let response: GenerateContentResponse;\n\n        // Handle streaming and non-streaming responses\n        if (streamingRequested) {\n          const result = await generateContentStream(\n            modelVersion,\n            generateContentRequest,\n            clientOpt\n          );\n\n          const chunks: CandidateData[] = [];\n          for await (const item of result.stream) {\n            (item as GenerateContentResponse).candidates?.forEach(\n              (candidate) => {\n                const c = fromGeminiCandidate(candidate, chunks);\n                chunks.push(c);\n                sendChunk({\n                  index: c.index,\n                  content: c.message.content,\n                });\n              }\n            );\n          }\n          response = await result.response;\n        } else {\n          response = await generateContent(\n            modelVersion,\n            generateContentRequest,\n            clientOpt\n          );\n        }\n\n        if (!response.candidates?.length) {\n          throw new GenkitError({\n            status: 'FAILED_PRECONDITION',\n            message: 'No valid candidates returned.',\n          });\n        }\n\n        const candidateData = response.candidates.map((c) =>\n          fromGeminiCandidate(c)\n        );\n\n        return {\n          candidates: candidateData,\n          custom: response,\n          usage: {\n            ...getBasicUsageStats(request.messages, candidateData),\n            inputTokens: response.usageMetadata?.promptTokenCount,\n            outputTokens: response.usageMetadata?.candidatesTokenCount,\n            thoughtsTokens: response.usageMetadata?.thoughtsTokenCount,\n            totalTokens: response.usageMetadata?.totalTokenCount,\n            cachedContentTokens:\n              response.usageMetadata?.cachedContentTokenCount,\n          },\n        };\n      };\n\n      // If debugTraces is enabled, we wrap the actual model call with a span,\n      // add raw API params as for input.\n      const msg = toGeminiMessage(messages[messages.length - 1], ref);\n      return pluginOptions?.experimental_debugTraces\n        ? await runInNewSpan(\n            {\n              metadata: {\n                name: streamingRequested ? 'sendMessageStream' : 'sendMessage',\n              },\n            },\n            async (metadata) => {\n              metadata.input = {\n                apiEndpoint: getVertexAIUrl({\n                  includeProjectAndLocation: false,\n                  resourcePath: '',\n                  clientOptions: clientOpt,\n                }),\n                cache: {},\n                model: modelVersion,\n                generateContentOptions: generateContentRequest,\n                parts: msg.parts,\n                options: clientOpt,\n              };\n              const response = await callGemini();\n              metadata.output = response.custom;\n              return response;\n            }\n          )\n        : await callGemini();\n    }\n  );\n}\n\nexport const TEST_ONLY = {\n  KNOWN_GEMINI_MODELS,\n  KNOWN_IMAGE_MODELS,\n  KNOWN_MODELS,\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAgBA,oBAAoE;AACpE,mBAUO;AACP,wBAAqC;AACrC,oBAAqC;AACrC,qBAA6B;AAC7B,wBAMO;AACP,oBAIO;AACP,IAAAA,qBAAuD;AAavD,mBAMO;AAEA,MAAM,uBAAuB,gBACjC,OAAO;AAAA,EACN,UAAU,gBAAE,KAAK;AAAA;AAAA,IAEf;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA;AAAA,IAEA;AAAA,EACF,CAAC;AAAA,EACD,WAAW,gBAAE,KAAK;AAAA,IAChB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AACH,CAAC,EACA,YAAY;AAEf,MAAM,wBAAwB,gBAC3B,OAAO;AAAA,EACN,WAAW,gBACR,OAAO;AAAA,IACN,WAAW,gBAAE,OAAO,EAAE,SAAS,0BAA0B,EAAE,SAAS;AAAA,IACpE,UAAU,gBACP,OAAO,EACP,SAAS,uCAAuC,EAChD,SAAS;AAAA,IACZ,aAAa,gBACV,OAAO,EACP;AAAA,MACC;AAAA,IAIF;AAAA,EACJ,CAAC,EACA,SAAS,qCAAqC,EAC9C,YAAY;AAAA,EACf,oBAAoB,gBACjB,QAAQ,EACR;AAAA,IACC;AAAA,EAEF,EACC,SAAS;AACd,CAAC,EACA,YAAY;AAEf,MAAM,8BAA8B,gBACjC,OAAO;AAAA,EACN,oBAAoB,gBACjB,QAAQ,EACR;AAAA,IACC;AAAA,EAEF,EACC,SAAS;AACd,CAAC,EACA,YAAY;AAMR,MAAM,qBAAqB,0CAA6B,OAAO;AAAA,EACpE,QAAQ,gBACL,OAAO,EACP,SAAS,wDAAwD,EACjE,SAAS;AAAA,EACZ,QAAQ,gBACL,OAAO,gBAAE,OAAO,CAAC,EACjB,SAAS,EACT,SAAS,8DAA8D;AAAA,EAC1E,aAAa,gBACV,OAAO,EACP,IAAI,CAAG,EACP,IAAI,CAAG,EACP;AAAA,IACC,gDAAmC,cACjC;AAAA,EACJ,EACC,SAAS;AAAA,EACZ,MAAM,gBACH,OAAO,EACP,IAAI,CAAC,EACL,IAAI,CAAG,EACP;AAAA,IACC,gDAAmC,OAAO;AAAA,EAC5C,EACC,SAAS;AAAA,EACZ,UAAU,gBACP,OAAO,EACP,SAAS,uCAAuC,EAChD,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EA8BZ,gBAAgB,gBACb,MAAM,oBAAoB,EAC1B;AAAA,IACC;AAAA,EAEF,EACC,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAoBZ,iBAAiB,sBAAsB;AAAA,IACrC;AAAA,EAEF,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaX,uBAAuB,4BAA4B;AAAA,IACjD;AAAA,EACF,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAeX,uBAAuB,gBACpB,OAAO;AAAA,IACN,MAAM,gBAAE,KAAK,CAAC,oBAAoB,QAAQ,OAAO,MAAM,CAAC,EAAE,SAAS;AAAA,IACnE,sBAAsB,gBAAE,MAAM,gBAAE,OAAO,CAAC,EAAE,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAMnD,6BAA6B,gBAAE,QAAQ,EAAE,SAAS;AAAA,EACpD,CAAC,EACA;AAAA,IACC;AAAA,EAMF,EACC,YAAY,EACZ,SAAS;AAAA;AAAA;AAAA;AAAA,EAIZ,iBAAiB,gBACd,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,IAKN,QAAQ,gBACL,OAAO;AAAA,MACN,UAAU,gBAAE,OAAO,EAAE,SAAS;AAAA,MAC9B,WAAW,gBAAE,OAAO,EAAE,SAAS;AAAA,IACjC,CAAC,EACA,SAAS,2DAA2D,EACpE,SAAS;AAAA;AAAA;AAAA;AAAA,IAIZ,cAAc,gBAAE,OAAO,EAAE,SAAS;AAAA,EACpC,CAAC,EACA,YAAY,EACZ,SAAS;AAAA,EACZ,gBAAgB,gBACb,OAAO;AAAA,IACN,iBAAiB,gBACd,QAAQ,EACR;AAAA,MACC;AAAA,IAGF,EACC,SAAS;AAAA,IACZ,gBAAgB,gBACb,OAAO,EACP,IAAI,CAAC,EACL,IAAI,KAAK,EACT;AAAA,MACC;AAAA,IAOF,EACC,SAAS;AAAA,IACZ,eAAe,gBACZ,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAC9B;AAAA,MACC;AAAA,IAGF,EACC,SAAS;AAAA,EACd,CAAC,EACA,YAAY,EACZ,SAAS;AACd,CAAC,EAAE,YAAY;AAoCR,MAAM,0BAA0B,mBAAmB,OAAO;AAAA,EAC/D,aAAa,gBACV,OAAO;AAAA,IACN,aAAa,gBACV,KAAK;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC,EACA,SAAS;AAAA,IACZ,WAAW,gBAAE,KAAK,CAAC,MAAM,MAAM,IAAI,CAAC,EAAE,SAAS;AAAA,EACjD,CAAC,EACA,YAAY,EACZ,SAAS;AACd,CAAC,EAAE,YAAY;AAQf,SAAS,UACP,MACA,MACA,eAAiC,oBACC;AAClC,aAAO,uBAAS;AAAA,IACd,MAAM,YAAY,IAAI;AAAA,IACtB;AAAA,IACA,MAAM,QAAQ;AAAA,MACZ,UAAU;AAAA,QACR,WAAW;AAAA,QACX,OAAO;AAAA,QACP,OAAO;AAAA,QACP,YAAY;AAAA,QACZ,YAAY;AAAA,QACZ,aAAa;AAAA,MACf;AAAA,IACF;AAAA,EACF,CAAC;AACH;AAEA,MAAM,gBAAgB,UAAU,QAAQ;AACxC,MAAM,sBAAsB;AAAA,EAC1B;AAAA,EACA;AAAA,EACA;AACF;AAEO,MAAM,sBAAsB;AAAA,EACjC,wBAAwB,UAAU,sBAAsB;AAAA,EACxD,yBAAyB,UAAU,uBAAuB;AAAA,EAC1D,kBAAkB,UAAU,gBAAgB;AAAA,EAC5C,oBAAoB,UAAU,kBAAkB;AAAA,EAChD,wBAAwB,UAAU,sBAAsB;AAAA,EACxD,oBAAoB,UAAU,kBAAkB;AAAA,EAChD,yBAAyB,UAAU,uBAAuB;AAAA,EAC1D,6BAA6B,UAAU,2BAA2B;AACpE;AAGO,SAAS,kBAAkB,OAA0C;AAC1E,SAAO,CAAC,EACN,OAAO,WAAW,SAAS,KAC3B,CAAC,MAAM,SAAS,WAAW,KAC3B,CAAC,MAAM,SAAS,QAAQ;AAE5B;AAEO,MAAM,qBAAqB;AAAA,EAChC,8BAA8B;AAAA,IAC5B;AAAA,IACA,EAAE,GAAG,oBAAoB,KAAK;AAAA,IAC9B;AAAA,EACF;AAAA,EACA,0BAA0B;AAAA,IACxB;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAGO,SAAS,iBAAiB,OAAyC;AACxE,SAAO,CAAC,EAAE,OAAO,WAAW,SAAS,KAAK,MAAM,SAAS,QAAQ;AACnE;AAEA,MAAM,eAAe;AAAA,EACnB,GAAG;AAAA,EACH,GAAG;AACL;AAGO,SAAS,MACd,SACA,SAAuB,CAAC,GACU;AAClC,QAAM,WAAO,6BAAe,OAAO;AAEnC,MAAI,iBAAiB,IAAI,GAAG;AAC1B,eAAO,uBAAS;AAAA,MACd,MAAM,YAAY,IAAI;AAAA,MACtB;AAAA,MACA,cAAc;AAAA,MACd,MAAM,EAAE,GAAG,oBAAoB,KAAK;AAAA,IACtC,CAAC;AAAA,EACH;AAEA,aAAO,uBAAS;AAAA,IACd,MAAM,YAAY,IAAI;AAAA,IACtB;AAAA,IACA,cAAc;AAAA,IACd,MAAM;AAAA,MACJ,GAAG,cAAc;AAAA,IACnB;AAAA,EACF,CAAC;AACH;AAEO,SAAS,YAAY,QAAmC;AAC7D,QAAM,6BAA6B;AAAA,IACjC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,SAAO,OACJ;AAAA,IACC,CAAC,OACE,sBAAkB,wBAAU,EAAE,IAAI,CAAC,KAClC,qBAAiB,wBAAU,EAAE,IAAI,CAAC,MACpC,CAAC,2BAA2B,aAAS,wBAAU,EAAE,IAAI,KAAK,EAAE;AAAA,EAChE,EACC,IAAI,CAAC,MAAM;AACV,UAAM,MAAM,MAAM,EAAE,IAAI;AACxB,eAAO,mCAAoB;AAAA,MACzB,MAAM,IAAI;AAAA,MACV,MAAM,IAAI;AAAA,MACV,cAAc,IAAI;AAAA,IACpB,CAAC;AAAA,EACH,CAAC;AACL;AAEO,SAAS,gBACd,eACA,eACA;AACA,SAAO,OAAO,KAAK,YAAY,EAAE;AAAA,IAAI,CAAC,SACpC,YAAY,MAAM,eAAe,aAAa;AAAA,EAChD;AACF;AAKO,SAAS,YACd,MACA,eACA,eACa;AACb,QAAM,MAAM,MAAM,IAAI;AACtB,QAAM,cAAiC,CAAC;AACxC,MAAI,IAAI,MAAM,UAAU,OAAO;AAE7B,gBAAY;AAAA,UACV,wCAAqB;AAAA,QACnB,UAAU,OAAO,OAAO;AAAA,QACxB,QAAQ,CAAC,SAAS;AAChB,cAAI;AACF,kBAAM,MAAM,IAAI,IAAI,KAAK,MAAM,GAAG;AAClC;AAAA;AAAA,cAEE,CAAC,mBAAmB,eAAe,UAAU,EAAE;AAAA,gBAC7C,IAAI;AAAA,cACN;AAAA;AAEA,qBAAO;AAAA,UACX,QAAQ;AAAA,UAAC;AACT,iBAAO;AAAA,QACT;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AAEA,aAAO,cAAAC;AAAA,IACL;AAAA,MACE,MAAM,IAAI;AAAA,MACV,GAAG,IAAI;AAAA,MACP,cAAc,IAAI;AAAA,MAClB,KAAK;AAAA,IACP;AAAA,IACA,OAAO,SAAS,EAAE,oBAAoB,WAAW,YAAY,MAAM;AACjE,UAAI,YAAY,EAAE,GAAG,eAAe,QAAQ,YAAY;AAGxD,YAAM,WAAW,gBAAgB,QAAQ,QAAQ;AACjD,UAAI,SAAS,WAAW,EAAG,OAAM,IAAI,MAAM,uBAAuB;AAGlE,UAAI,oBAAyC;AAC7C,YAAM,gBAAgB,SAAS,KAAK,CAAC,MAAM,EAAE,SAAS,QAAQ;AAC9D,UAAI,eAAe;AACjB,iBAAS,OAAO,SAAS,QAAQ,aAAa,GAAG,CAAC;AAClD,gCAAoB,6CAA0B,aAAa;AAAA,MAC7D;AAEA,YAAM,gBAA8B,EAAE,GAAG,QAAQ,OAAO;AAExD,YAAM;AAAA,QACJ,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,QACA,SAAS;AAAA,QACT;AAAA,QACA,OAAO;AAAA,QACP;AAAA,QACA;AAAA,QACA;AAAA,QACA,QAAQ;AAAA,QACR,GAAG;AAAA,MACL,IAAI;AAEJ,sBAAY,sCAAwB,WAAW;AAAA,QAC7C;AAAA,QACA,QAAQ;AAAA,MACV,CAAC;AAED,YAAM,aAAS,mCAAe,gBAAgB;AAE9C,YAAM,QAAgB,CAAC;AACvB,UAAI,QAAQ,OAAO,QAAQ;AACzB,cAAM,KAAK;AAAA,UACT,sBAAsB,QAAQ,MAAM,IAAI,8BAAY;AAAA,QACtD,CAAC;AAAA,MACH;AAEA,UAAI;AACJ,UAAI,uBAAuB;AACzB,qBAAa;AAAA,UACX,uBAAuB;AAAA,YACrB,GAAG;AAAA,YACH,sBAAsB,sBAAsB;AAAA,YAC5C,UAAM,4CAAyB,sBAAsB,IAAI;AAAA,UAC3D;AAAA,QACF;AAAA,MACF,WAAW,QAAQ,YAAY;AAC7B,qBAAa;AAAA,UACX,uBAAuB;AAAA,YACrB,UAAM,4CAAyB,QAAQ,UAAU;AAAA,UACnD;AAAA,QACF;AAAA,MACF;AAEA,UAAI,iBAAiB;AACnB,YAAI,CAAC,YAAY;AACf,uBAAa,CAAC;AAAA,QAChB;AACA,mBAAW,kBAAkB,gBAAgB,eAAe;AAAA,MAC9D;AAGA,YAAM,YACH,QAAQ,QAAQ,WAAW,UAAU,CAAC,CAAC,QAAQ,QAAQ,WACxD,MAAM,WAAW;AAEnB,UAAI,iBAAiB;AACnB,cAAM,KAAK,GAAI,eAAyB;AAAA,MAC1C;AAEA,UAAI,uBAAuB;AAEzB,YAAI,IAAI,KAAK,WAAW,qBAAqB,GAAG;AAC9C,gBAAM,KAAK;AAAA,YACT;AAAA,UAEF,CAA8B;AAAA,QAChC,OAAO;AACL,gBAAM,KAAK;AAAA,YACT,cAAc;AAAA,UAChB,CAA8B;AAAA,QAChC;AAAA,MACF;AAEA,UAAI,iBAAiB;AACnB,cAAM,aACJ,gBAAgB,UAAU,cACzB,cAAc,QAAQ,YACnB,cAAc,YACd;AACN,cAAM,YACJ,gBAAgB,UAAU,aACzB,cAAc,QAAQ,aACnB,cAAc,WACd;AACN,cAAM,eAAe,gBAAgB,UAAU;AAC/C,YAAI,CAAC,cAAc,CAAC,aAAa,CAAC,cAAc;AAC9C,gBAAM,IAAI,0BAAY;AAAA,YACpB,QAAQ;AAAA,YACR,SACE;AAAA,UACJ,CAAC;AAAA,QACH;AACA,cAAM,YAAY,YAAY,UAAU,cAAc,SAAS,8CAA8C,YAAY;AACzH,cAAM,KAAK;AAAA,UACT,WAAW;AAAA,YACT,gBAAgB;AAAA,cACd;AAAA,YACF;AAAA,YACA,oBAAoB,gBAAgB;AAAA,UACtC;AAAA,QACF,CAAC;AAAA,MACH;AAEA,YAAM,yBAAiD;AAAA,QACrD;AAAA,QACA,kBAAkB;AAAA,UAChB,GAAG;AAAA,UACH,gBAAgB,QAAQ,cAAc;AAAA,UACtC,kBAAkB,WAAW,qBAAqB;AAAA,QACpD;AAAA,QACA;AAAA,QACA;AAAA,QACA,oBAAgB,2CAAuB,cAAc;AAAA,QACrD,UAAU,SAAS,IAAI,CAAC,gBAAY,mCAAgB,SAAS,GAAG,CAAC;AAAA,QACjE;AAAA,MACF;AAEA,YAAM,eAAe,yBAAqB,6BAAe,GAAG;AAE5D,UAAI,YAAY,QAAQ,QAAQ,aAAa;AAC3C,YAAI,eAAe,sBAAsB;AACvC,iCAAuB,iBAAkB,qBAAiB;AAAA,YACxD,QAAQ,OAAO;AAAA,UACjB;AAAA,QACF,OAAO;AACL,iCAAuB,iBAAkB,qBACvC,QAAQ,OAAO;AAAA,QACnB;AAAA,MACF;AAEA,YAAM,aAAa,YAAY;AAC7B,YAAI;AAGJ,YAAI,oBAAoB;AACtB,gBAAM,SAAS,UAAM;AAAA,YACnB;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAEA,gBAAM,SAA0B,CAAC;AACjC,2BAAiB,QAAQ,OAAO,QAAQ;AACtC,YAAC,KAAiC,YAAY;AAAA,cAC5C,CAAC,cAAc;AACb,sBAAM,QAAI,uCAAoB,WAAW,MAAM;AAC/C,uBAAO,KAAK,CAAC;AACb,0BAAU;AAAA,kBACR,OAAO,EAAE;AAAA,kBACT,SAAS,EAAE,QAAQ;AAAA,gBACrB,CAAC;AAAA,cACH;AAAA,YACF;AAAA,UACF;AACA,qBAAW,MAAM,OAAO;AAAA,QAC1B,OAAO;AACL,qBAAW,UAAM;AAAA,YACf;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAAA,QACF;AAEA,YAAI,CAAC,SAAS,YAAY,QAAQ;AAChC,gBAAM,IAAI,0BAAY;AAAA,YACpB,QAAQ;AAAA,YACR,SAAS;AAAA,UACX,CAAC;AAAA,QACH;AAEA,cAAM,gBAAgB,SAAS,WAAW;AAAA,UAAI,CAAC,UAC7C,uCAAoB,CAAC;AAAA,QACvB;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,OAAO;AAAA,YACL,OAAG,iCAAmB,QAAQ,UAAU,aAAa;AAAA,YACrD,aAAa,SAAS,eAAe;AAAA,YACrC,cAAc,SAAS,eAAe;AAAA,YACtC,gBAAgB,SAAS,eAAe;AAAA,YACxC,aAAa,SAAS,eAAe;AAAA,YACrC,qBACE,SAAS,eAAe;AAAA,UAC5B;AAAA,QACF;AAAA,MACF;AAIA,YAAM,UAAM,mCAAgB,SAAS,SAAS,SAAS,CAAC,GAAG,GAAG;AAC9D,aAAO,eAAe,2BAClB,UAAM;AAAA,QACJ;AAAA,UACE,UAAU;AAAA,YACR,MAAM,qBAAqB,sBAAsB;AAAA,UACnD;AAAA,QACF;AAAA,QACA,OAAO,aAAa;AAClB,mBAAS,QAAQ;AAAA,YACf,iBAAa,8BAAe;AAAA,cAC1B,2BAA2B;AAAA,cAC3B,cAAc;AAAA,cACd,eAAe;AAAA,YACjB,CAAC;AAAA,YACD,OAAO,CAAC;AAAA,YACR,OAAO;AAAA,YACP,wBAAwB;AAAA,YACxB,OAAO,IAAI;AAAA,YACX,SAAS;AAAA,UACX;AACA,gBAAM,WAAW,MAAM,WAAW;AAClC,mBAAS,SAAS,SAAS;AAC3B,iBAAO;AAAA,QACT;AAAA,MACF,IACA,MAAM,WAAW;AAAA,IACvB;AAAA,EACF;AACF;AAEO,MAAM,YAAY;AAAA,EACvB;AAAA,EACA;AAAA,EACA;AACF;","names":["import_converters","pluginModel"]}