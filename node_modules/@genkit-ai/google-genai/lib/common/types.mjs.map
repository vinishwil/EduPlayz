{"version":3,"sources":["../../src/common/types.ts"],"sourcesContent":["/**\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { z } from 'genkit';\n\n/** Function calling mode. */\nexport enum FunctionCallingMode {\n  /** Unspecified function calling mode. This value should not be used. */\n  MODE_UNSPECIFIED = 'MODE_UNSPECIFIED',\n  /**\n   * Default model behavior, model decides to predict either function calls\n   * or natural language response.\n   */\n  AUTO = 'AUTO',\n  /**\n   * Model is constrained to always predicting function calls only.\n   * If \"allowedFunctionNames\" are set, the predicted function calls will be\n   * limited to any one of \"allowedFunctionNames\", else the predicted\n   * function calls will be any one of the provided \"function_declarations\".\n   */\n  ANY = 'ANY',\n  /**\n   * Model will not predict any function calls. Model behavior is same as when\n   * not passing any function declarations.\n   */\n  NONE = 'NONE',\n}\n\nexport function isObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === 'object' && value !== null;\n}\n\n/**\n * The reason why the response is blocked.\n */\nexport enum BlockReason {\n  /** Unspecified block reason. */\n  BLOCKED_REASON_UNSPECIFIED = 'BLOCKED_REASON_UNSPECIFIED', // GoogleAI\n  BLOCK_REASON_UNSPECIFIED = 'BLOCK_REASON_UNSPECIFIED', // VertexAI\n\n  /** Candidates blocked due to safety. */\n  SAFETY = 'SAFETY',\n  /** Candidates blocked due to other reason. */\n  OTHER = 'OTHER',\n  /** terminology blocklist. */\n  BLOCKLIST = 'BLOCKLIST',\n  /** Candidates blocked due to prohibited content. */\n  PROHIBITED_CONTENT = 'PROHIBITED_CONTENT',\n}\n\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nexport enum HarmCategory {\n  HARM_CATEGORY_UNSPECIFIED = 'HARM_CATEGORY_UNSPECIFIED',\n  HARM_CATEGORY_HATE_SPEECH = 'HARM_CATEGORY_HATE_SPEECH',\n  HARM_CATEGORY_SEXUALLY_EXPLICIT = 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n  HARM_CATEGORY_HARASSMENT = 'HARM_CATEGORY_HARASSMENT',\n  HARM_CATEGORY_DANGEROUS_CONTENT = 'HARM_CATEGORY_DANGEROUS_CONTENT',\n  HARM_CATEGORY_CIVIC_INTEGRITY = 'HARM_CATEGORY_CIVIC_INTEGRITY',\n}\n\n/**\n * Probability based thresholds levels for blocking.\n */\nexport enum HarmBlockThreshold {\n  /** Unspecified harm block threshold. */\n  HARM_BLOCK_THRESHOLD_UNSPECIFIED = 'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n  /** Block low threshold and above (i.e. block more). */\n  BLOCK_LOW_AND_ABOVE = 'BLOCK_LOW_AND_ABOVE',\n  /** Block medium threshold and above. */\n  BLOCK_MEDIUM_AND_ABOVE = 'BLOCK_MEDIUM_AND_ABOVE',\n  /** Block only high threshold (i.e. block less). */\n  BLOCK_ONLY_HIGH = 'BLOCK_ONLY_HIGH',\n  /** Block none. */\n  BLOCK_NONE = 'BLOCK_NONE',\n  /** Turn off the safety filter. */\n  OFF = 'OFF',\n}\n\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nexport enum HarmProbability {\n  /** Probability is unspecified. */\n  HARM_PROBABILITY_UNSPECIFIED = 'HARM_PROBABILITY_UNSPECIFIED',\n  /** Content has a negligible chance of being unsafe. */\n  NEGLIGIBLE = 'NEGLIGIBLE',\n  /** Content has a low chance of being unsafe. */\n  LOW = 'LOW',\n  /** Content has a medium chance of being unsafe. */\n  MEDIUM = 'MEDIUM',\n  /** Content has a high chance of being unsafe. */\n  HIGH = 'HIGH',\n}\n\n/**\n * The mode of the predictor to be used in dynamic retrieval.\n * @public\n */\nexport enum DynamicRetrievalMode {\n  // Unspecified function calling mode. This value should not be used.\n  MODE_UNSPECIFIED = 'MODE_UNSPECIFIED',\n  // Run retrieval only when system decides it is necessary.\n  MODE_DYNAMIC = 'MODE_DYNAMIC',\n}\n\n/**\n * Specifies the dynamic retrieval configuration for the given source.\n * @public\n */\nexport declare interface DynamicRetrievalConfig {\n  /**\n   * The mode of the predictor to be used in dynamic retrieval.\n   */\n  mode?: DynamicRetrievalMode;\n  /**\n   * The threshold to be used in dynamic retrieval. If not set, a system default\n   * value is used.\n   */\n  dynamicThreshold?: number;\n}\n\n/**\n * Defines a retrieval tool that model can call to access external knowledge.\n */\nexport declare interface GoogleSearchRetrievalTool {\n  /** Optional. {@link GoogleSearchRetrieval}. */\n  googleSearchRetrieval?: GoogleSearchRetrieval;\n  googleSearch?: GoogleSearchRetrieval;\n}\nexport function isGoogleSearchRetrievalTool(\n  tool: Tool\n): tool is GoogleSearchRetrievalTool {\n  return (\n    (tool as GoogleSearchRetrievalTool).googleSearchRetrieval !== undefined ||\n    (tool as GoogleSearchRetrievalTool).googleSearch !== undefined\n  );\n}\n\nexport declare interface UrlContextTool {\n  urlContext?: {};\n}\n\n/**\n * The FileSearch tool that retrieves knowledge from Semantic Retrieval corpora.\n * Files are imported to Semantic Retrieval corpora using the ImportFile API\n */\nexport declare interface FileSearchTool {\n  fileSearch: FileSearch;\n}\n\nexport declare interface FileSearch {\n  /**\n   * The names of the fileSearchStores to retrieve from.\n   * Example: fileSearchStores/my-file-search-store-123\n   */\n  fileSearchStoreNames: string[];\n  /**\n   * Metadata filter to apply to the semantic retrieval documents and chunks.\n   */\n  metadataFilter?: string;\n  /**\n   * The number of semantic retrieval chunks to retrieve.\n   */\n  topK?: number;\n}\nexport function isFileSearchTool(tool: Tool): tool is FileSearchTool {\n  return (tool as FileSearchTool).fileSearch !== undefined;\n}\n\n/**\n * Grounding support.\n */\nexport declare interface GroundingSupport {\n  /** Optional. Segment of the content this support belongs to. */\n  segment?: GroundingSupportSegment;\n  /**\n   * Optional. A array of indices (into {@link GroundingChunk}) specifying the\n   * citations associated with the claim. For instance [1,3,4] means\n   * that grounding_chunk[1], grounding_chunk[3],\n   * grounding_chunk[4] are the retrieved content attributed to the claim.\n   */\n  groundingChunkIndices?: number[];\n  /**\n   * Confidence score of the support references. Ranges from 0 to 1. 1 is the\n   * most confident. This list must have the same size as the\n   * groundingChunkIndices.\n   */\n  confidenceScores?: number[];\n}\n\n/**\n * Grounding support segment.\n */\nexport declare interface GroundingSupportSegment {\n  /** Optional. The index of a Part object within its parent Content object. */\n  partIndex?: number;\n  /**\n   * Optional. Start index in the given Part, measured in bytes.\n   * Offset from the start of the Part, inclusive, starting at zero.\n   */\n  startIndex?: number;\n  /**\n   * Optional. End index in the given Part, measured in bytes.\n   * Offset from the start of the Part, exclusive, starting at zero.\n   */\n  endIndex?: number;\n  /** Optional. The text corresponding to the segment from the response. */\n  text?: string;\n}\n\n/**\n * Harm severity levels\n */\nexport enum HarmSeverity {\n  /** Harm severity unspecified. */\n  HARM_SEVERITY_UNSPECIFIED = 'HARM_SEVERITY_UNSPECIFIED',\n  /** Negligible level of harm severity. */\n  HARM_SEVERITY_NEGLIGIBLE = 'HARM_SEVERITY_NEGLIGIBLE',\n  /** Low level of harm severity. */\n  HARM_SEVERITY_LOW = 'HARM_SEVERITY_LOW',\n  /** Medium level of harm severity. */\n  HARM_SEVERITY_MEDIUM = 'HARM_SEVERITY_MEDIUM',\n  /** High level of harm severity. */\n  HARM_SEVERITY_HIGH = 'HARM_SEVERITY_HIGH',\n}\n\n/**\n * Safety rating corresponding to the generated content.\n */\nexport declare interface SafetyRating {\n  /** The harm category. {@link HarmCategory} */\n  category?: HarmCategory;\n  /** The harm probability. {@link HarmProbability} */\n  probability?: HarmProbability;\n  /** The harm probability score. */\n  probabilityScore?: number;\n  /** The harm severity.level {@link HarmSeverity} */\n  severity?: HarmSeverity;\n  /** The harm severity score. */\n  severityScore?: number;\n}\n\n/**\n * If the prompt was blocked, this will be populated with `blockReason` and\n * the relevant `safetyRatings`.\n */\nexport declare interface PromptFeedback {\n  /** The reason why the response is blocked. {@link BlockReason}. */\n  blockReason: BlockReason;\n  /** Array of {@link SafetyRating} */\n  safetyRatings: SafetyRating[];\n  /** A readable block reason message. */\n  blockReasonMessage?: string;\n}\n\n/**\n * URI based data.\n */\nexport declare interface FileData {\n  /** The IANA standard MIME type of the source data. */\n  mimeType: string;\n  /** URI of the file. */\n  fileUri: string;\n}\n\n/**\n * Raw media bytes sent directly in the request. Text should not be sent as\n * raw bytes.\n */\nexport declare interface GenerativeContentBlob {\n  /**\n   * The MIME type of the source data. The only accepted values: \"image/png\" or\n   * \"image/jpeg\".\n   */\n  mimeType: string;\n  /** Base64 encoded data. */\n  data: string;\n}\n\n/**\n * A predicted FunctionCall returned from the model that contains a string\n * representating the FunctionDeclaration.name with the parameters and their\n * values.\n */\nexport declare interface FunctionCall {\n  /**\n   * The unique id of the function call. If populated, the client to execute the\n   * `function_call` and return the response with the matching `id`.\n   */\n  id?: string;\n  /** The name of the function specified in FunctionDeclaration.name. */\n  name?: string;\n  /** The arguments to pass to the function. */\n  args?: object;\n  /** Optional. The partial argument value of the function call. If provided, represents the arguments/fields that are streamed incrementally. */\n  partialArgs?: PartialArg[];\n  /** Optional. Whether this is the last part of the FunctionCall. If true, another partial message for the current FunctionCall is expected to follow. */\n  willContinue?: boolean;\n}\n\n/** Partial argument value of the function call. This data type is not supported in Gemini API. */\nexport declare interface PartialArg {\n  /** Optional. Represents a null value. */\n  nullValue?: 'NULL_VALUE';\n  /** Optional. Represents a double value. */\n  numberValue?: number;\n  /** Optional. Represents a string value. */\n  stringValue?: string;\n  /** Optional. Represents a boolean value. */\n  boolValue?: boolean;\n  /** Required. A JSON Path (RFC 9535) to the argument being streamed. https://datatracker.ietf.org/doc/html/rfc9535. e.g. \"$.foo.bar[0].data\". */\n  jsonPath?: string;\n  /** Optional. Whether this is not the last part of the same json_path. If true, another PartialArg message for the current json_path is expected to follow. */\n  willContinue?: boolean;\n}\n/**\n * The result output of a FunctionCall that contains a string representing\n * the FunctionDeclaration.name and a structured JSON object containing any\n * output from the function call. It is used as context to the model.\n */\nexport declare interface FunctionResponse {\n  /** Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`. */\n  id?: string;\n  /** The name of the function specified in FunctionDeclaration.name. */\n  name: string;\n  /** The expected response from the model. */\n  response: object;\n  /** List of parts that constitute a function response. Each part may\n      have a different IANA MIME type. */\n  parts?: FunctionResponsePart[];\n}\n\n/**\n * A datatype containing media that is part of a `FunctionResponse` message.\n *\n * A `FunctionResponsePart` consists of data which has an associated datatype. A\n * `FunctionResponsePart` can only contain one of the accepted types in\n * `FunctionResponsePart.data`.\n *\n * A `FunctionResponsePart` must have a fixed IANA MIME type identifying the\n * type and subtype of the media if the `inline_data` field is filled with raw\n * bytes.\n */\nexport class FunctionResponsePart {\n  /** Optional. Inline media bytes. */\n  inlineData?: FunctionResponseBlob;\n}\n\n/**\n * Raw media bytes for function response.\n *\n * Text should not be sent as raw bytes, use the FunctionResponse.response field.\n */\nexport class FunctionResponseBlob {\n  /** Required. The IANA standard MIME type of the source data. */\n  mimeType?: string;\n  /** Required. Inline media bytes.\n   * @remarks Encoded as base64 string. */\n  data?: string;\n  /** Optional. Display name of the blob.\n      Used to provide a label or filename to distinguish blobs. */\n  displayName?: string;\n}\n\n/**\n * The list of OpenAPI data types\n * as defined by https://swagger.io/docs/specification/data-models/data-types/\n */\nexport enum SchemaType {\n  /** String type. */\n  STRING = 'STRING',\n  /** Number type. */\n  NUMBER = 'NUMBER',\n  /** Integer type. */\n  INTEGER = 'INTEGER',\n  /** Boolean type. */\n  BOOLEAN = 'BOOLEAN',\n  /** Array type. */\n  ARRAY = 'ARRAY',\n  /** Object type. */\n  OBJECT = 'OBJECT',\n}\n\nexport declare interface Schema {\n  type?: SchemaType;\n  format?: string;\n  title?: string;\n  description?: string;\n  nullable?: boolean;\n  items?: Schema;\n  minItems?: number;\n  maxItems?: number;\n  properties?: Record<string, Schema>;\n  enum?: string[];\n  required?: string[];\n  example?: unknown;\n}\n\n/**\n * Schema for parameters passed to {@link FunctionDeclaration.parameters}.\n */\nexport declare interface FunctionDeclarationSchema {\n  /** The type of the parameter. */\n  type: SchemaType;\n  /** The format of the parameter. */\n  properties: Record<string, Schema>;\n  /** Optional. Description of the parameter. */\n  description?: string;\n  /** Optional. Array of required parameters. */\n  required?: string[];\n}\n\nexport declare interface FunctionDeclaration {\n  /**\n   * The name of the function to call. Must start with a letter or an\n   * underscore. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with\n   * a max length of 64.\n   */\n  name: string;\n  /**\n   * Optional. Description and purpose of the function. Model uses it to decide\n   * how and whether to call the function.\n   */\n  description?: string;\n  /**\n   * Optional. Describes the parameters to this function in JSON Schema Object\n   * format. Reflects the Open API 3.03 Parameter Object. string Key: the name\n   * of the parameter. Parameter names are case sensitive. Schema Value: the\n   * Schema defining the type used for the parameter. For function with no\n   * parameters, this can be left unset.\n   *\n   * @example with 1 required and 1 optional parameter: type: OBJECT properties:\n   * ```\n   * param1:\n   *\n   *   type: STRING\n   * param2:\n   *\n   *  type: INTEGER\n   * required:\n   *\n   *   - param1\n   * ```\n   */\n  parameters?: FunctionDeclarationSchema;\n}\n\n/**\n * Metadata on the generation request's token usage.\n */\nexport declare interface UsageMetadata {\n  /** Optional. Number of tokens in the request. */\n  promptTokenCount?: number;\n  /** Optional. Number of tokens in the response(s). */\n  candidatesTokenCount?: number;\n  /** Optional. Total number of tokens. */\n  totalTokenCount?: number;\n  /** Optional. Number of tokens in the cached content. */\n  cachedContentTokenCount?: number;\n  /** Optional. Number of tokens present in thoughts output. */\n  thoughtsTokenCount?: number;\n}\n\nexport const TaskTypeSchema = z.enum([\n  'RETRIEVAL_DOCUMENT',\n  'RETRIEVAL_QUERY',\n  'SEMANTIC_SIMILARITY',\n  'CLASSIFICATION',\n  'CLUSTERING',\n]);\n\nexport type TaskType = z.infer<typeof TaskTypeSchema>;\n\n/**\n * Reason that a candidate finished.\n * @public\n */\nexport enum FinishReason {\n  // Default value. This value is unused.\n  FINISH_REASON_UNSPECIFIED = 'FINISH_REASON_UNSPECIFIED',\n  // Natural stop point of the model or provided stop sequence.\n  STOP = 'STOP',\n  // The maximum number of tokens as specified in the request was reached.\n  MAX_TOKENS = 'MAX_TOKENS',\n  // The candidate content was flagged for safety reasons.\n  SAFETY = 'SAFETY',\n  // The candidate content was flagged for recitation reasons.\n  RECITATION = 'RECITATION',\n  // The candidate content was flagged for using an unsupported language.\n  LANGUAGE = 'LANGUAGE',\n  // Token generation stopped because the content contains forbidden terms.\n  BLOCKLIST = 'BLOCKLIST',\n  // Token generation stopped for potentially containing prohibited content.\n  PROHIBITED_CONTENT = 'PROHIBITED_CONTENT',\n  // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).\n  SPII = 'SPII',\n  // The function call generated by the model is invalid.\n  MALFORMED_FUNCTION_CALL = 'MALFORMED_FUNCTION_CALL',\n  // At least one thought signature from a previous call is missing.\n  MISSING_THOUGHT_SIGNATURE = 'MISSING_THOUGHT_SIGNATURE',\n  // Unknown reason.\n  OTHER = 'OTHER',\n}\n\n/**\n * Represents a whole or partial calendar date, such as a birthday. The time of\n * day and time zone are either specified elsewhere or are insignificant. The\n * date is relative to the Gregorian Calendar. This can represent one of the\n * following:\n *\n *   A full date, with non-zero year, month, and day values.\n *   A month and day, with a zero year (for example, an anniversary).\n *   A year on its own, with a zero month and a zero day.\n *   A year and month, with a zero day (for example, a credit card expiration\n *   date).\n */\nexport declare interface GoogleDate {\n  /**\n   * Year of the date. Must be from 1 to 9999, or 0 to specify a date without a\n   * year.\n   */\n  year?: number;\n  /**\n   * Month of the date. Must be from 1 to 12, or 0 to specify a year without a\n   * month and day.\n   */\n  month?: number;\n  /**\n   * Day of the date. Must be from 1 to 31 and valid for the year and month.\n   * or 0 to specify a year by itself or a year and month where the day isn't\n   * significant\n   */\n  day?: number;\n}\n\n/**\n * Source attributions for content.\n */\nexport declare interface CitationSource {\n  /** Optional. Start index into the content. */\n  startIndex?: number;\n  /** Optional. End index into the content. */\n  endIndex?: number;\n  /** Optional. Url reference of the attribution. */\n  uri?: string;\n  /** Optional. License of the attribution. */\n  license?: string;\n  /** Optional. Title of the attribution. VertexAI only.*/\n  title?: string;\n  /** Optional. Publication date of the attribution. VertexAI only */\n  publicationDate?: GoogleDate;\n}\n\n/**\n * A collection of source attributions for a piece of content.\n */\nexport declare interface CitationMetadata {\n  /** Array of {@link CitationSource}. */\n  citations?: CitationSource[]; // VertexAI\n  citationSources?: CitationSource[]; // GoogleAI\n}\n\n/**\n * Google search entry point.\n */\nexport declare interface SearchEntryPoint {\n  /**\n   * Optional. Web content snippet that can be embedded in a web page or an app\n   * webview.\n   */\n  renderedContent?: string;\n  /** Optional. Base64 encoded JSON representing array of tuple. */\n  sdkBlob?: string;\n}\n\n/**\n * Grounding chunk from the web.\n */\nexport declare interface GroundingChunkWeb {\n  /** Optional. URI reference of the grounding chunk. */\n  uri?: string;\n  /** Optional. Title of the grounding chunk. */\n  title?: string;\n}\n\n/**\n * Grounding chunk from context retrieved by the retrieval tools.\n */\nexport declare interface GroundingChunkRetrievedContext {\n  /** Optional. URI reference of the attribution. */\n  uri?: string;\n  /** Optional. Title of the attribution. */\n  title?: string;\n}\n\n/**\n * Grounding chunk.\n */\nexport declare interface GroundingChunk {\n  /** Optional. Grounding chunk from the web. */\n  web?: GroundingChunkWeb;\n  /**\n   * Optional. Grounding chunk from context retrieved by the retrieval tools. (VertexAI only)\n   */\n  retrievedContext?: GroundingChunkRetrievedContext;\n}\n\n/**\n * Metadata related to retrieval in the grounding flow. GoogleAI only.\n * @public\n */\nexport declare interface RetrievalMetadata {\n  /**\n   * Score indicating how likely information from google search could help\n   * answer the prompt. The score is in the range [0, 1], where 0 is the least\n   * likely and 1 is the most likely. This score is only populated when google\n   * search grounding and dynamic retrieval is enabled. It will becompared to\n   * the threshold to determine whether to trigger google search.\n   */\n  googleSearchDynamicRetrievalScore?: number;\n}\n\n/**\n * A collection of grounding attributions for a piece of content.\n */\nexport declare interface GroundingMetadata {\n  /** Optional. Google search entry for the following-up web searches. {@link SearchEntryPoint} */\n  searchEntryPoint?: SearchEntryPoint;\n  /**\n   * Optional. Array of supporting references retrieved from specified\n   * grounding source. {@link GroundingChunk}.\n   */\n  groundingChunks?: GroundingChunk[];\n  /** Optional. Array of grounding support. {@link GroundingSupport}. */\n  groundingSupports?: GroundingSupport[];\n  /** Optional. Web search queries for the following-up web search. */\n  webSearchQueries?: string[];\n  /** Optional. Queries executed by the retrieval tools. VertexAI only*/\n  retrievalQueries?: string[];\n  /**\n   * Optional. Metadata related to retrieval in the grounding flow. GoogleAI only.\n   */\n  retrievalMetadata?: RetrievalMetadata;\n}\n\n/**\n * @public\n */\nexport enum ExecutableCodeLanguage {\n  LANGUAGE_UNSPECIFIED = 'LANGUAGE_UNSPECIFIED',\n  PYTHON = 'PYTHON',\n}\n\n/**\n * Code generated by the model that is meant to be executed, where the result\n * is returned to the model.\n * Only generated when using the code execution tool, in which the code will\n * be automatically executed, and a corresponding `CodeExecutionResult` will\n * also be generated.\n *\n * @public\n */\nexport declare interface ExecutableCode {\n  /**\n   * Programming language of the `code`.\n   */\n  language: ExecutableCodeLanguage;\n  /**\n   * The code to be executed.\n   */\n  code: string;\n}\n\n/**\n * Possible outcomes of code execution.\n * @public\n */\nexport enum Outcome {\n  /**\n   * Unspecified status. This value should not be used.\n   */\n  OUTCOME_UNSPECIFIED = 'OUTCOME_UNSPECIFIED',\n  /**\n   * Code execution completed successfully.\n   */\n  OUTCOME_OK = 'OUTCOME_OK',\n  /**\n   * Code execution finished but with a failure. `stderr` should contain the\n   * reason.\n   */\n  OUTCOME_FAILED = 'OUTCOME_FAILED',\n  /**\n   * Code execution ran for too long, and was cancelled. There may or may not\n   * be a partial output present.\n   */\n  OUTCOME_DEADLINE_EXCEEDED = 'OUTCOME_DEADLINE_EXCEEDED',\n}\n\n/**\n * Result of executing the `ExecutableCode`.\n * Only generated when using code execution, and always follows a `Part`\n * containing the `ExecutableCode`.\n * @public\n */\nexport declare interface CodeExecutionResult {\n  /**\n   * Outcome of the code execution.\n   */\n  outcome: Outcome;\n  /**\n   * Contains stdout when code execution is successful, stderr or other\n   * description otherwise.\n   */\n  output: string;\n}\n\n/**\n * Can be added in the same part as video media to specify\n * which part of the video to consider and how many frames\n * per second to analyze. VertexAI only.\n */\nexport declare interface VideoMetadata {\n  /**\n   * The video offset to start at. e.g. '3.5s'\n   */\n  startOffset?: string;\n  /**\n   * The video offset to end at e.g. '10.5s'\n   */\n  endOffset?: string;\n  /**\n   * The number of frames to consider per second\n   * 0.0 to 24.0.\n   */\n  fps?: number;\n}\n\nexport enum MediaResolutionLevel {\n  MEDIA_RESOUTION_LOW = 'MEDIA_RESOUTION_LOW',\n  MEDIA_RESOLUTION_MEDIUM = 'MEDIA_RESOLUTION_MEDIUM',\n  MEDIA_RESOLUTION_HIGH = 'MEDIA_RESOLUTION_HIGH',\n}\n\nexport declare interface MediaResolution {\n  level?: MediaResolutionLevel;\n}\n\n/**\n * This is a Gemini Part. (Users never see this\n * structure, it is just built by the converters.)\n */\nexport declare interface Part {\n  text?: string;\n  inlineData?: GenerativeContentBlob;\n  functionCall?: FunctionCall;\n  functionResponse?: FunctionResponse;\n  fileData?: FileData;\n  thought?: boolean;\n  thoughtSignature?: string;\n  executableCode?: ExecutableCode;\n  codeExecutionResult?: CodeExecutionResult;\n  videoMetadata?: VideoMetadata;\n  mediaResolution?: MediaResolution;\n}\n\n/**\n * The base structured datatype containing multi-part content of a message.\n */\nexport declare interface Content {\n  /** The producer of the content. */\n  role: string;\n  /** Array of {@link Part}. */\n  parts: Part[];\n}\n\n/**\n * Candidate for the logprobs token and score.\n * @public\n */\nexport declare interface LogprobsCandidate {\n  /** The candidate's token string value. */\n  token: string;\n  /** The candidate's token id value. */\n  tokenID: number;\n  /** The candidate's log probability. */\n  logProbability: number;\n}\n\n/**\n * Candidates with top log probabilities at each decoding step\n */\nexport declare interface TopCandidates {\n  /** Sorted by log probability in descending order. */\n  candidates: LogprobsCandidate[];\n}\n\n/**\n * Logprobs Result\n * @public\n */\nexport declare interface LogprobsResult {\n  /** Length = total number of decoding steps. */\n  topCandidates: TopCandidates[];\n  /**\n   * Length = total number of decoding steps.\n   * The chosen candidates may or may not be in topCandidates.\n   */\n  chosenCandidates: LogprobsCandidate[];\n}\n\n/**\n * A candidate returned as part of a GenerateContentResponse.\n * @public\n */\nexport declare interface GenerateContentCandidate {\n  index: number;\n  content: Content;\n  finishReason?: FinishReason;\n  finishMessage?: string;\n  safetyRatings?: SafetyRating[];\n  citationMetadata?: CitationMetadata;\n  /** Average log probability score of the candidate. GoogleAI only*/\n  avgLogprobs?: number;\n  /** Log-likelihood scores for the response tokens and top tokens. GoogleAI only*/\n  logprobsResult?: LogprobsResult;\n  /** Search grounding metadata. */\n  groundingMetadata?: GroundingMetadata;\n}\n\n/**\n * Individual response from generateContent and generateContentStream.\n * `generateContentStream()` will return one in each chunk until\n * the stream is done.\n * @public\n */\nexport declare interface GenerateContentResponse {\n  /** Candidate responses from the model. */\n  candidates?: GenerateContentCandidate[];\n  /** The prompt's feedback related to the content filters. */\n  promptFeedback?: PromptFeedback;\n  /** Metadata on the generation request's token usage. */\n  usageMetadata?: UsageMetadata;\n}\n\n/**\n * A FunctionDeclarationsTool is a piece of code that enables the system to\n * interact with external systems to perform an action, or set of actions,\n * outside of knowledge and scope of the model.\n * @public\n */\nexport declare interface FunctionDeclarationsTool {\n  /**\n   * Optional. One or more function declarations\n   * to be passed to the model along with the current user query. Model may\n   * decide to call a subset of these functions by populating\n   * [FunctionCall][content.part.functionCall] in the response. User should\n   * provide a [FunctionResponse][content.part.functionResponse] for each\n   * function call in the next turn. Based on the function responses, Model will\n   * generate the final response back to the user. Maximum 64 function\n   * declarations can be provided.\n   */\n  functionDeclarations?: FunctionDeclaration[];\n}\nexport function isFunctionDeclarationsTool(\n  tool: Tool\n): tool is FunctionDeclarationsTool {\n  return (tool as FunctionDeclarationsTool).functionDeclarations !== undefined;\n}\n\n/**\n * Google AI Only. Enables the model to execute code as part of generation.\n * @public\n */\nexport declare interface CodeExecutionTool {\n  /**\n   * Provide an empty object to enable code execution. This field may have\n   * subfields added in the future.\n   */\n  codeExecution: {};\n}\nexport function isCodeExecutionTool(tool: Tool): tool is CodeExecutionTool {\n  return (tool as CodeExecutionTool).codeExecution !== undefined;\n}\n\n/**\n * Vertex AI Only. Retrieve from Vertex AI Search datastore for grounding.\n */\nexport declare interface VertexAISearch {\n  /**\n   * Fully-qualified Vertex AI Search's datastore resource ID. See\n   * https://cloud.google.com/vertex-ai-search-and-conversation\n   *\n   * @example\n   * \"projects/<>/locations/<>/collections/<>/dataStores/<>\"\n   */\n  datastore: string;\n}\n\n/**\n * Vertex AI Only. Config of Vertex RagStore grounding checking.\n */\nexport declare interface RagResource {\n  /**\n   * Optional. Vertex RAG Store corpus resource name.\n   *\n   * @example\n   * `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`\n   */\n  ragCorpus?: string;\n\n  /**\n   * Optional. Set this field to select the files under the ragCorpora for\n   * retrieval.\n   */\n  ragFileIds?: string[];\n}\n\n/** Vertex AI Only. */\nexport declare interface VertexRagStore {\n  /**\n   * Optional. List of corpora for retrieval. Currently only support one corpus\n   * or multiple files from one corpus. In the future we may open up multiple\n   * corpora support.\n   */\n  ragResources?: RagResource[];\n\n  /** Optional. Number of top k results to return from the selected corpora. */\n  similarityTopK?: number;\n\n  /**\n   * Optional. If set this field, results with vector distance smaller than\n   * this threshold will be returned.\n   */\n  vectorDistanceThreshold?: number;\n}\n\n/**\n * Vertex AI Only. Defines a retrieval tool that model can call to access external knowledge.\n */\nexport declare interface Retrieval {\n  /**\n   * Optional. Set to use data source powered by Vertex AI Search. {@link\n   * VertexAISearch}.\n   */\n  vertexAiSearch?: VertexAISearch;\n\n  /** Optional. Set to use data source powered by Vertex RAG store. */\n  vertexRagStore?: VertexRagStore;\n\n  /**\n   * Optional. Disable using the result from this tool in detecting grounding\n   * attribution. This does not affect how the result is given to the model for\n   * generation.\n   */\n  disableAttribution?: boolean;\n}\n\n/**\n * Vertex AI Only. Defines a retrieval tool that model can call to access external knowledge.\n */\nexport declare interface RetrievalTool {\n  /** Optional. {@link Retrieval}. */\n  retrieval?: Retrieval;\n}\nexport function isRetrievalTool(tool: Tool): tool is RetrievalTool {\n  return (tool as RetrievalTool).retrieval !== undefined;\n}\n\nexport declare interface GoogleMaps {\n  enableWidget: boolean;\n}\nexport declare interface GoogleMapsTool {\n  googleMaps?: GoogleMaps;\n}\nexport function isGoogleMapsTool(tool: Tool): tool is GoogleMapsTool {\n  return (tool as GoogleMapsTool).googleMaps !== undefined;\n}\n\n/**\n * Tool to retrieve public web data for grounding, powered by Google.\n */\nexport declare interface GoogleSearchRetrieval {\n  /** Specifies the dynamic retrieval configuration for the given source. */\n  dynamicRetrievalConfig?: DynamicRetrievalConfig;\n}\n\n/**\n * Defines a tool that model can call to access external knowledge.\n * @public\n */\nexport declare type Tool =\n  | FunctionDeclarationsTool\n  | RetrievalTool // Vertex AI Only\n  | GoogleMapsTool // Vertex AI Only\n  | CodeExecutionTool // Google AI Only\n  | FileSearchTool // Google AI Only\n  | UrlContextTool // Google AI Only\n  | GoogleSearchRetrievalTool;\n\n/**\n * Configuration options for model generation and outputs.\n */\nexport declare interface GenerationConfig {\n  /** Optional. If true, the timestamp of the audio will be included in the response. */\n  audioTimestamp?: boolean;\n  /** Optional. Number of candidates to generate. */\n  candidateCount?: number;\n  /** Optional. Stop sequences. */\n  stopSequences?: string[];\n  /** Optional. The maximum number of output tokens to generate per message. */\n  maxOutputTokens?: number;\n  /** Optional. Controls the randomness of predictions. */\n  temperature?: number;\n  /** Optional. If specified, nucleus sampling will be used. */\n  topP?: number;\n  /** Optional. If specified, topK sampling will be used. */\n  topK?: number;\n  /**\n   * Google AI only. Presence penalty applied to the next token's logprobs if the token has\n   * already been seen in the response.\n   */\n  presencePenalty?: number;\n  /**\n   * Optional. Positive values penalize tokens that repeatedly appear in the generated text, decreasing the probability of repeating content.\n   * This maximum value for frequencyPenalty is up to, but not including, 2.0. Its minimum value is -2.0.\n  frequencyPenalty?: number;\n  /**\n   * Google AI Only. If True, export the logprobs results in response.\n   */\n  responseLogprobs?: boolean;\n  /**\n   * Google AI Only. Valid if responseLogProbs is set to True. This will set the number of top\n   * logprobs to return at each decoding step in the logprobsResult.\n   */\n  logprobs?: number;\n  /**\n   * Optional. Output response mimetype of the generated candidate text.\n   * Supported mimetype:\n   * - `text/plain`: (default) Text output.\n   * - `application/json`: JSON response in the candidates.\n   * The model needs to be prompted to output the appropriate response type,\n   * otherwise the behavior is undefined.\n   */\n  responseMimeType?: string;\n\n  /**\n   * Optional. The schema that generated candidate text must follow.  For more\n   * information, see\n   * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output.\n   * If set, a compatible responseMimeType must also be set.\n   */\n  responseSchema?: Schema;\n\n  /**\n   * Optional. Output schema of the generated response. This is an alternative to\n   * `response_schema` that accepts [JSON Schema](https://json-schema.org/).\n   *\n   * If set, `response_schema` must be omitted, but `response_mime_type` is\n   * required.\n   *\n   * While the full JSON Schema may be sent, not all features are supported.\n   * Specifically, only the following properties are supported:\n   *\n   * - `$id`\n   * - `$defs`\n   * - `$ref`\n   * - `$anchor`\n   * - `type`\n   * - `format`\n   * - `title`\n   * - `description`\n   * - `enum` (for strings and numbers)\n   * - `items`\n   * - `prefixItems`\n   * - `minItems`\n   * - `maxItems`\n   * - `minimum`\n   * - `maximum`\n   * - `anyOf`\n   * - `oneOf` (interpreted the same as `anyOf`)\n   * - `properties`\n   * - `additionalProperties`\n   * - `required`\n   *\n   * The non-standard `propertyOrdering` property may also be set.\n   *\n   * Cyclic references are unrolled to a limited degree and, as such, may only\n   * be used within non-required properties. (Nullable properties are not\n   * sufficient.) If `$ref` is set on a sub-schema, no other properties, except\n   * for than those starting as a `$`, may be set.\n   */\n  responseJsonSchema?: Record<string, any>;\n}\n\n/**\n * Safety setting that can be sent as part of request parameters.\n * @public\n */\nexport declare interface SafetySetting {\n  category: HarmCategory;\n  threshold: HarmBlockThreshold;\n}\n\nexport declare interface FunctionCallingConfig {\n  /** Optional. Function calling mode. */\n  mode?: FunctionCallingMode;\n\n  /**\n   * Optional. Function names to call. Only set when the Mode is ANY. Function\n   * names should match [FunctionDeclaration.name]. With mode set to ANY, model\n   * will predict a function call from the set of function names provided.\n   */\n  allowedFunctionNames?: string[];\n\n  /**\n   * When set to true, arguments of a single function call will be streamed out\n   * in multiple parts/contents/responses. Partial parameter results will be\n   * returned in the [FunctionCall.partial_args] field.\n   */\n  streamFunctionCallArguments?: boolean;\n}\n\nexport declare interface LatLng {\n  latitude?: number;\n  longitude?: number;\n}\n\nexport declare interface RetrievalConfig {\n  latLng?: LatLng;\n  languageCode?: string;\n}\n\n/** This config is shared for all tools provided in the request. */\nexport declare interface ToolConfig {\n  /** Function calling config. */\n  functionCallingConfig?: FunctionCallingConfig;\n  /** Retrieval config */\n  retrievalConfig?: RetrievalConfig;\n}\n\nexport declare interface GenerateContentRequest {\n  /** Array of {@link Content}.*/\n  contents: Content[];\n  /**\n   * Optional. The name of the cached content used as context to serve the prediction.\n   * This is the name of a `CachedContent` and not the cache object itself.\n   */\n  cachedContent?: string;\n  /** Optional.  {@link GenerationConfig}. */\n  generationConfig?: GenerationConfig;\n  /**\n   * Optional. Vertex AI Only. Custom metadata labels for organizing API calls and managing costs at scale. See\n   * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls\n   */\n  labels?: Record<string, string>;\n  /** Optional. Array of {@link SafetySetting}. */\n  safetySettings?: SafetySetting[];\n  /**\n   * Optional. The user provided system instructions for the model.\n   * Note: only text should be used in parts of {@link Content}\n   */\n  systemInstruction?: string | Part | Content;\n  /** Optional. Array of {@link Tool}. */\n  tools?: Tool[];\n  /** Optional. This config is shared for all tools provided in the request. */\n  toolConfig?: ToolConfig;\n}\n\n/**\n * Result from calling generateContentStream.\n * It contains both the stream and the final aggregated response.\n * @public\n */\nexport declare interface GenerateContentStreamResult {\n  stream: AsyncGenerator<GenerateContentResponse>;\n  response: Promise<GenerateContentResponse>;\n}\n\nexport declare interface ImagenParameters {\n  sampleCount?: number;\n  aspectRatio?: string;\n  negativePrompt?: string; // Vertex only\n  seed?: number; // Vertex only\n  language?: string; // Vertex only\n  personGeneration?: string;\n  safetySetting?: string; // Vertex only\n  addWatermark?: boolean; // Vertex only\n  storageUri?: string; // Vertex only\n}\n\nexport declare interface ImagenPredictRequest {\n  instances: ImagenInstance[];\n  parameters: ImagenParameters;\n}\n\nexport declare interface ImagenPredictResponse {\n  predictions: ImagenPrediction[];\n}\n\nexport declare interface ImagenPrediction {\n  bytesBase64Encoded: string;\n  mimeType: string;\n}\n\nexport declare interface ImagenInstance {\n  prompt: string;\n  image?: { bytesBase64Encoded: string };\n  mask?: { image?: { bytesBase64Encoded: string } };\n}\n"],"mappings":"AAgBA,SAAS,SAAS;AAGX,IAAK,sBAAL,kBAAKA,yBAAL;AAEL,EAAAA,qBAAA,sBAAmB;AAKnB,EAAAA,qBAAA,UAAO;AAOP,EAAAA,qBAAA,SAAM;AAKN,EAAAA,qBAAA,UAAO;AAnBG,SAAAA;AAAA,GAAA;AAsBL,SAAS,SAAS,OAAkD;AACzE,SAAO,OAAO,UAAU,YAAY,UAAU;AAChD;AAKO,IAAK,cAAL,kBAAKC,iBAAL;AAEL,EAAAA,aAAA,gCAA6B;AAC7B,EAAAA,aAAA,8BAA2B;AAG3B,EAAAA,aAAA,YAAS;AAET,EAAAA,aAAA,WAAQ;AAER,EAAAA,aAAA,eAAY;AAEZ,EAAAA,aAAA,wBAAqB;AAZX,SAAAA;AAAA,GAAA;AAmBL,IAAK,eAAL,kBAAKC,kBAAL;AACL,EAAAA,cAAA,+BAA4B;AAC5B,EAAAA,cAAA,+BAA4B;AAC5B,EAAAA,cAAA,qCAAkC;AAClC,EAAAA,cAAA,8BAA2B;AAC3B,EAAAA,cAAA,qCAAkC;AAClC,EAAAA,cAAA,mCAAgC;AANtB,SAAAA;AAAA,GAAA;AAYL,IAAK,qBAAL,kBAAKC,wBAAL;AAEL,EAAAA,oBAAA,sCAAmC;AAEnC,EAAAA,oBAAA,yBAAsB;AAEtB,EAAAA,oBAAA,4BAAyB;AAEzB,EAAAA,oBAAA,qBAAkB;AAElB,EAAAA,oBAAA,gBAAa;AAEb,EAAAA,oBAAA,SAAM;AAZI,SAAAA;AAAA,GAAA;AAmBL,IAAK,kBAAL,kBAAKC,qBAAL;AAEL,EAAAA,iBAAA,kCAA+B;AAE/B,EAAAA,iBAAA,gBAAa;AAEb,EAAAA,iBAAA,SAAM;AAEN,EAAAA,iBAAA,YAAS;AAET,EAAAA,iBAAA,UAAO;AAVG,SAAAA;AAAA,GAAA;AAiBL,IAAK,uBAAL,kBAAKC,0BAAL;AAEL,EAAAA,sBAAA,sBAAmB;AAEnB,EAAAA,sBAAA,kBAAe;AAJL,SAAAA;AAAA,GAAA;AA+BL,SAAS,4BACd,MACmC;AACnC,SACG,KAAmC,0BAA0B,UAC7D,KAAmC,iBAAiB;AAEzD;AA6BO,SAAS,iBAAiB,MAAoC;AACnE,SAAQ,KAAwB,eAAe;AACjD;AA8CO,IAAK,eAAL,kBAAKC,kBAAL;AAEL,EAAAA,cAAA,+BAA4B;AAE5B,EAAAA,cAAA,8BAA2B;AAE3B,EAAAA,cAAA,uBAAoB;AAEpB,EAAAA,cAAA,0BAAuB;AAEvB,EAAAA,cAAA,wBAAqB;AAVX,SAAAA;AAAA,GAAA;AAkIL,MAAM,qBAAqB;AAAA;AAAA,EAEhC;AACF;AAOO,MAAM,qBAAqB;AAAA;AAAA,EAEhC;AAAA;AAAA;AAAA,EAGA;AAAA;AAAA;AAAA,EAGA;AACF;AAMO,IAAK,aAAL,kBAAKC,gBAAL;AAEL,EAAAA,YAAA,YAAS;AAET,EAAAA,YAAA,YAAS;AAET,EAAAA,YAAA,aAAU;AAEV,EAAAA,YAAA,aAAU;AAEV,EAAAA,YAAA,WAAQ;AAER,EAAAA,YAAA,YAAS;AAZC,SAAAA;AAAA,GAAA;AA+FL,MAAM,iBAAiB,EAAE,KAAK;AAAA,EACnC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,CAAC;AAQM,IAAK,eAAL,kBAAKC,kBAAL;AAEL,EAAAA,cAAA,+BAA4B;AAE5B,EAAAA,cAAA,UAAO;AAEP,EAAAA,cAAA,gBAAa;AAEb,EAAAA,cAAA,YAAS;AAET,EAAAA,cAAA,gBAAa;AAEb,EAAAA,cAAA,cAAW;AAEX,EAAAA,cAAA,eAAY;AAEZ,EAAAA,cAAA,wBAAqB;AAErB,EAAAA,cAAA,UAAO;AAEP,EAAAA,cAAA,6BAA0B;AAE1B,EAAAA,cAAA,+BAA4B;AAE5B,EAAAA,cAAA,WAAQ;AAxBE,SAAAA;AAAA,GAAA;AA2KL,IAAK,yBAAL,kBAAKC,4BAAL;AACL,EAAAA,wBAAA,0BAAuB;AACvB,EAAAA,wBAAA,YAAS;AAFC,SAAAA;AAAA,GAAA;AA6BL,IAAK,UAAL,kBAAKC,aAAL;AAIL,EAAAA,SAAA,yBAAsB;AAItB,EAAAA,SAAA,gBAAa;AAKb,EAAAA,SAAA,oBAAiB;AAKjB,EAAAA,SAAA,+BAA4B;AAlBlB,SAAAA;AAAA,GAAA;AA4DL,IAAK,uBAAL,kBAAKC,0BAAL;AACL,EAAAA,sBAAA,yBAAsB;AACtB,EAAAA,sBAAA,6BAA0B;AAC1B,EAAAA,sBAAA,2BAAwB;AAHd,SAAAA;AAAA,GAAA;AA8HL,SAAS,2BACd,MACkC;AAClC,SAAQ,KAAkC,yBAAyB;AACrE;AAaO,SAAS,oBAAoB,MAAuC;AACzE,SAAQ,KAA2B,kBAAkB;AACvD;AAkFO,SAAS,gBAAgB,MAAmC;AACjE,SAAQ,KAAuB,cAAc;AAC/C;AAQO,SAAS,iBAAiB,MAAoC;AACnE,SAAQ,KAAwB,eAAe;AACjD;","names":["FunctionCallingMode","BlockReason","HarmCategory","HarmBlockThreshold","HarmProbability","DynamicRetrievalMode","HarmSeverity","SchemaType","FinishReason","ExecutableCodeLanguage","Outcome","MediaResolutionLevel"]}